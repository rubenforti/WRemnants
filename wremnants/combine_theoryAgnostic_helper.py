from utilities import logging,common, boostHistHelpers as hh
from utilities.io_tools import input_tools
from wremnants import syst_tools,theory_tools
from wremnants.helicity_utils import axis_helicity_multidim
import narf.ioutils
import numpy as np
import re
import hist
import h5py

logger = logging.child_logger(__name__)

class TheoryAgnosticHelper(object):
    def __init__(self, card_tool, externalArgs=None):
        self.card_tool = card_tool
        toCheck = ['signal_samples', 'signal_samples_noOutAcc']
        for group in toCheck:
            if group not in self.card_tool.procGroups:
                raise ValueError(f"Must define '{group}' procGroup in CardTool for theory agnostic fit")
        self.args = externalArgs
        self.label = "Label"
        self.passSystToFakes = True
        self.separateOutOfAccSignal = False
        self.poi_axes = []

    def configure_polVar(self,
                         label,
                         passSystToFakes,
                         hasSeparateOutOfAcceptanceSignal):
        self.label = label
        self.passSystToFakes = passSystToFakes
        self.separateOutOfAccSignal = hasSeparateOutOfAcceptanceSignal

    def configure_normVar(self,
                          label,
                          passSystToFakes,
                          poi_axes):
        self.label = label
        self.passSystToFakes = passSystToFakes
        self.poi_axes = poi_axes

    def add_theoryAgnostic_polVar_uncertainty(self):
        coeffs = ["UL"] + [f"A{i}" for i in range(5)]
        groupName = f"polVar{self.label}"
        for genVcharge in ["minus", "plus"]:
            for coeffKey in coeffs:
                self.card_tool.addSystematic(f"theoryAgnosticWithPol_{coeffKey}_{genVcharge}",
                                       group=groupName,
                                       mirror=False,
                                       symmetrize="average" if self.args.symmetrizePolVar else None,
                                       passToFakes=False if self.args.noPolVarOnFake else self.passSystToFakes,
                                       processes=["signal_samples_noOutAcc" if self.separateOutOfAccSignal else "signal_samples"],
                                       baseName=f"{groupName}_{coeffKey}_{genVcharge}_",
                                       noConstraint=True,
                                       systAxes=["nPolVarSyst", "downUpVar"],
                                       labelsByAxis=["v", "downUpVar"],
                                       #splitGroup={f"{groupName}_{coeffKey}" : f"{groupName}_{coeffKey}"}
                                       )

    def add_muRmuF_polVar_uncertainty(self):
        coeffs = [f"A{i}" for i in range(8)]
        signalGroupName = "muRmuFPolVarW" if self.label == "W" else "muRmuFPolVarZ"
        nonSignalGroupName = "muRmuFPolVarZ" if self.label == "W" else "muRmuFPolVarW"
        for coeffKey in coeffs:
            self.card_tool.addSystematic(f"{signalGroupName}_{coeffKey}",
                                   group=signalGroupName,
                                   mirror=False,
                                   passToFakes=self.passSystToFakes,
                                   processes=["signal_samples_inctau_noOutAcc" if self.separateOutOfAccSignal else "signal_samples_inctau"],
                                   baseName=f"{signalGroupName}_{coeffKey}_",
                                   noConstraint=False,
                                   systAxes=["nPolVarSyst", "downUpVar"],
                                   labelsByAxis=["v", "downUpVar"],
                                   #splitGroup={f"{groupName}_{coeffKey}" : f"{groupName}_{coeffKey}"}
                                   )

        for coeffKey in coeffs:
            self.card_tool.addSystematic(f"{nonSignalGroupName}_{coeffKey}",
                                   group=nonSignalGroupName,
                                   mirror=False,
                                   passToFakes=self.passSystToFakes,
                                   processes=["nonsignal_samples_inctau_noOutAcc" if self.separateOutOfAccSignal else "nonsignal_samples_inctau"],
                                   baseName=f"{nonSignalGroupName}_{coeffKey}_",
                                   noConstraint=False,
                                   systAxes=["nPolVarSyst", "downUpVar"],
                                   labelsByAxis=["v", "downUpVar"],
                                   #splitGroup={f"{groupName}_{coeffKey}" : f"{groupName}_{coeffKey}"}
                                   )

    def apply_theoryAgnostic_normVar_uncertainty(self, scale_hists, sign, sum_axes=[], rebin_axes=[],helicities=[],scale=1.):

        def apply_transformations(h, scale_hist):
            sum2nom = {ax: hist.tag.Slicer()[::hist.sum] for ax in self.poi_axes}
            nom_hist = h[sum2nom]

            values = scale_hist.values()
            # values[:-1,:-1,3+1] = values[:-1,:-1,3+1]*2 #rescale sigma3 and keep fixed
            #rescale if necessary
            for helicity in helicities:
                values[:-1,:-1,helicity+1] = values[:-1,:-1,helicity+1]*scale #don't rescale OOA
            scale_hist.values()[...] = values

            scaled_hist = hh.multiplyHists(h, scale_hist, flow=True)
            scaled_hist=scaled_hist[{ax: hist.tag.Slicer()[::hist.sum] for ax in sum_axes}]
            
            for rebin_axis in rebin_axes:
                edges = [scaled_hist.axes[rebin_axis].edges[0], scaled_hist.axes[rebin_axis].edges[-1]]
                scaled_hist = hh.rebinHist(scaled_hist, rebin_axis, edges)
                
            summed_hist = hh.addHists(nom_hist, scaled_hist)

            return summed_hist

        def slice_histogram(h):
            transformed_hists = {ax: hist.tag.Slicer()[::hist.sum] for ax in self.poi_axes}
            return h[transformed_hists]

        result = {}

        for g in self.card_tool.procGroups["signal_samples"]:
            if sign != "":
                if sign is not None:
                    for m in self.card_tool.datagroups.groups[g].members:
                        if sign in m.name:
                            scale_hist = scale_hists[m.name]
                            result[m.name] = lambda h, scale_hist=scale_hist: apply_transformations(h, scale_hist)
                        else:
                            result[m.name] = lambda h: slice_histogram(h)
                else:
                    scale_hist = scale_hists["WplusmunuPostVFP"]
                    result["WplusmunuPostVFP"] = lambda h, scale_hist=scale_hist: apply_transformations(h, scale_hist)
                    scale_hist = scale_hists["WminusmunuPostVFP"]
                    result["WminusmunuPostVFP"] = lambda h, scale_hist=scale_hist: apply_transformations(h, scale_hist)
            else:
                scale_hist = scale_hists["ZmumuPostVFP"]
                result["ZmumuPostVFP"] = lambda h, scale_hist=scale_hist: apply_transformations(h, scale_hist)
        return result

    def add_theoryAgnostic_normVar_uncertainty(self, flow=True):

        common_noi_args = dict(
            group = f"normXsec{self.label}",
            passToFakes = self.passSystToFakes
        )
        
        # open file with theory bands
        with h5py.File(f"{common.data_dir}/angularCoefficients/theoryband_variations_decorr_OOA_alphaS_wUL_new_ct18z.hdf5", "r") as ff:
            scale_hists = narf.ioutils.pickle_load_h5py(ff["theorybands"])

        # First do in acceptance bins, then OOA later (for OOA we need to group bins into macro regions)
        nuisanceBaseName = f"norm{self.label}"
        if self.label=="Z":
            sign_list = [""]
        else:
            sign_list = ["plus", "minus"]
        for sign in sign_list:
            self.card_tool.addSystematic("yieldsTheoryAgnostic",
                                rename=f"{nuisanceBaseName}{sign}",
                                **common_noi_args,
                                mirror=True,
                                symmetrize = None,
                                systAxes=self.poi_axes,
                                processes=["signal_samples"],
                                baseName=f"{nuisanceBaseName}{sign}_",
                                noConstraint=True if self.args.priorNormXsec < 0 else False,
                                scale=1,
                                formatWithValue=[None,None,"low"],
                                labelsByAxis=["PtV", "YVBin", "Helicity"],
                                systAxesFlow=["ptVgenSig","absYVgenSig"], # only bins in acceptance in this call
                                skipEntries=[{"helicitySig" : [6,7,8]}], # removing last three indices out of 9 (0,1,...,7,8) corresponding to A5,6,7
                                # splitGroup={f"{nuisanceBaseName}_Helicity{ihel}" : f".*{nuisanceBaseName}{sign}.*Helicity{ihel}" for ihel in [-1, 0, 1, 2, 3, 4]},
                                splitGroup={f"{nuisanceBaseName}{sign}" : f".*{nuisanceBaseName}{sign}"},
                                preOpMap=
                                    self.apply_theoryAgnostic_normVar_uncertainty(scale_hists,sign,helicities=self.args.helicitiesToInflate, scale=self.args.theoryAgnosticBandSize),
                                ),
            self.card_tool.addSystematic("yieldsTheoryAgnostic",
                            rename=f"{nuisanceBaseName}{sign}CorrAll",
                            **common_noi_args,
                            mirror=True,
                            symmetrize = None,
                            systAxes=["ptVgenSig","absYVgenSig"],
                            processes=["signal_samples"],
                            baseName=f"{nuisanceBaseName}{sign}CorrAll_",
                            noConstraint=True if self.args.priorNormXsec < 0 else False,
                            scale=1,
                            formatWithValue=[None,None,"low"],
                            #customizeNuisanceAttributes={".*AngCoeff4" : {"scale" : 1, "shapeType": "shapeNoConstraint"}},
                            labelsByAxis=["PtV", "YVBin", "Helicity"],
                            systAxesFlow=[], # only bins in acceptance in this call
                            skipEntries=[], # removing last three indices out of 9 (0,1,...,7,8) corresponding to A5,6,7
                            # splitGroup={f"{nuisanceBaseName}_Helicity{ihel}" : f".*{nuisanceBaseName}{sign}.*Helicity{ihel}" for ihel in [-1, 0, 1, 2, 3, 4]},
                            splitGroup={f"{nuisanceBaseName}{sign}CorrAll" : f".*{nuisanceBaseName}{sign}CorrAll"},
                            preOpMap=
                                    self.apply_theoryAgnostic_normVar_uncertainty(scale_hists,sign=sign,helicities=self.args.helicitiesToInflate, scale=self.args.theoryAgnosticBandSize,rebin_axes=["ptVgenSig","absYVgenSig"],sum_axes=["helicitySig"]),
                                ),
            
            self.card_tool.addSystematic("yieldsTheoryAgnostic",
                                rename=f"{nuisanceBaseName}CorrPt{sign}",
                                **common_noi_args,
                                mirror=True,
                                symmetrize = None,
                                systAxes=self.poi_axes,
                                processes=["signal_samples"],
                                baseName=f"{nuisanceBaseName}CorrPt{sign}_",
                                noConstraint=True if self.args.priorNormXsec < 0 else False,
                                scale=1,
                                formatWithValue=[None,None,"low"],
                                labelsByAxis=["PtV", "YVBin", "Helicity"],
                                systAxesFlow=[], # only bins in acceptance in this call
                                skipEntries=[{"helicitySig" : [0,6,7,8]}], # removing last three indices out of 9 (0,1,...,7,8) corresponding to A5,6,7
                                # splitGroup={f"{nuisanceBaseName}_Helicity{ihel}" : f".*{nuisanceBaseName}{sign}.*Helicity{ihel}" for ihel in [0, 1, 2, 3, 4]},
                                splitGroup={f"{nuisanceBaseName}CorrPt{sign}" : f".*{nuisanceBaseName}CorrPt{sign}"},
                                preOpMap=
                                    self.apply_theoryAgnostic_normVar_uncertainty(scale_hists,sign,helicities=self.args.helicitiesToInflate, scale=self.args.theoryAgnosticBandSize,rebin_axes=["ptVgenSig"]),
                                ),
            
            # self.card_tool.addSystematic("yieldsTheoryAgnostic",
            #                     rename=f"{nuisanceBaseName}CorrExtra1{sign}",
            #                     **common_noi_args,
            #                     mirror=True,
            #                     symmetrize = None,
            #                     systAxes=["helicitySig"],
            #                     processes=["signal_samples"],
            #                     baseName=f"{nuisanceBaseName}CorrExtra1{sign}_",
            #                     noConstraint=True if self.args.priorNormXsec < 0 else False,
            #                     scale=1,
            #                     formatWithValue=[None,None,"low"],
            #                     labelsByAxis=["PtV", "YVBin", "Helicity"],
            #                     systAxesFlow=[], # only bins in acceptance in this call
            #                     skipEntries=[{"helicitySig" : [0,6,7,8]}], # removing last three indices out of 9 (0,1,...,7,8) corresponding to A5,6,7
            #                     # splitGroup={f"{nuisanceBaseName}_Helicity{ihel}" : f".*{nuisanceBaseName}{sign}.*Helicity{ihel}" for ihel in [0, 1, 2, 3, 4]},
            #                     splitGroup={f"{nuisanceBaseName}CorrExtra1{sign}" : f".*{nuisanceBaseName}CorrExtra1{sign}"},
            #                     preOpMap=
            #                         self.apply_theoryAgnostic_normVar_uncertainty(scale_hists,sign,helicities=self.args.helicitiesToInflate, scale=self.args.theoryAgnosticBandSize,rebin_axes=["ptVgenSig","absYVgenSig"]),
            #                     ),
            
            # self.card_tool.addSystematic("yieldsTheoryAgnostic",
            #                     rename=f"{nuisanceBaseName}CorrExtra2{sign}",
            #                     **common_noi_args,
            #                     mirror=True,
            #                     symmetrize = None,
            #                     systAxes=["ptVgenSig","helicitySig"],
            #                     processes=["signal_samples"],
            #                     baseName=f"{nuisanceBaseName}CorrExtra2{sign}_",
            #                     noConstraint=True if self.args.priorNormXsec < 0 else False,
            #                     scale=1,
            #                     formatWithValue=[None,None,"low"],
            #                     labelsByAxis=["PtV", "YVBin", "Helicity"],
            #                     systAxesFlow=[], # only bins in acceptance in this call
            #                     skipEntries=[{"helicitySig" : [0,6,7,8]}], # removing last three indices out of 9 (0,1,...,7,8) corresponding to A5,6,7
            #                     # splitGroup={f"{nuisanceBaseName}_Helicity{ihel}" : f".*{nuisanceBaseName}{sign}.*Helicity{ihel}" for ihel in [0, 1, 2, 3, 4]},
            #                     splitGroup={f"{nuisanceBaseName}CorrExtra2{sign}" : f".*{nuisanceBaseName}CorrExtra2{sign}"},
            #                     preOpMap=
            #                         self.apply_theoryAgnostic_normVar_uncertainty(scale_hists,sign,helicities=self.args.helicitiesToInflate, scale=self.args.theoryAgnosticBandSize,rebin_axes=["absYVgenSig"]),
            #                     ),
        
        if not sign_list == [""]:
            self.card_tool.addSystematic("yieldsTheoryAgnostic",
                                rename=f"{nuisanceBaseName}CorrAllQ",
                                **common_noi_args,
                                mirror=True,
                                symmetrize = None,
                                systAxes=["ptVgenSig","absYVgenSig"],
                                processes=["signal_samples"],
                                baseName=f"{nuisanceBaseName}CorrAllQ_",
                                noConstraint=True if self.args.priorNormXsec < 0 else False,
                                scale=1.0,
                                formatWithValue=[None,None,"low"],
                                #customizeNuisanceAttributes={".*AngCoeff4" : {"scale" : 1, "shapeType": "shapeNoConstraint"}},
                                labelsByAxis=["PtV", "YVBin", "Helicity"],
                                systAxesFlow=[], # only bins in acceptance in this call
                                skipEntries=[], # removing last three indices out of 9 (0,1,...,7,8) corresponding to A5,6,7
                                # splitGroup={f"{nuisanceBaseName}_Helicity{ihel}" : f".*{nuisanceBaseName}.*Helicity{ihel}" for ihel in [-1, 0, 1, 2, 3, 4]},
                                splitGroup={f"{nuisanceBaseName}CorrAllQ" : f".*{nuisanceBaseName}CorrAllQ"},
                                preOpMap=
                                        self.apply_theoryAgnostic_normVar_uncertainty(scale_hists,sign=None,helicities=self.args.helicitiesToInflate, scale=self.args.theoryAgnosticBandSize, rebin_axes=["ptVgenSig","absYVgenSig"],sum_axes=["helicitySig"]),
                                    ),
            # self.card_tool.addSystematic("yieldsTheoryAgnostic",
            #                     rename=f"{nuisanceBaseName}CorrAllHelQ",
            #                     **common_noi_args,
            #                     mirror=True,
            #                     symmetrize = None,
            #                     systAxes=["helicitySig"],
            #                     processes=["signal_samples"],
            #                     baseName=f"{nuisanceBaseName}CorrAllHelQ_",
            #                     noConstraint=True if self.args.priorNormXsec < 0 else False,
            #                     scale=1.0,
            #                     formatWithValue=["low"],
            #                     #customizeNuisanceAttributes={".*AngCoeff4" : {"scale" : 1, "shapeType": "shapeNoConstraint"}},
            #                     labelsByAxis=["Helicity"],
            #                     systAxesFlow=[], # only bins in acceptance in this call
            #                     skipEntries=[6,7,8], # removing last three indices out of 9 (0,1,...,7,8) corresponding to A5,6,7
            #                     splitGroup={f"{nuisanceBaseName}_Helicity{ihel}" : f".*{nuisanceBaseName}.*Helicity{ihel}" for ihel in [-1, 0, 1, 2, 3, 4]},
            #                     # splitGroup={f"{nuisanceBaseName}CorrAllQ" : f".*{nuisanceBaseName}CorrAllQ"},
            #                     preOpMap=
            #                             self.apply_theoryAgnostic_normVar_uncertainty(scale_hists,sign=None,helicities=self.args.helicitiesToInflate, scale=self.args.theoryAgnosticBandSize, rebin_axes=["ptVgenSig","absYVgenSig"]),
            #                         ),
            # self.card_tool.addSystematic("yieldsTheoryAgnostic",
            #                     rename=f"{nuisanceBaseName}CorrPtQ",
            #                     **common_noi_args,
            #                     mirror=True,
            #                     symmetrize = None,
            #                     systAxes=self.poi_axes,
            #                     processes=["signal_samples"],
            #                     baseName=f"{nuisanceBaseName}CorrPtQ_",
            #                     noConstraint=True if self.args.priorNormXsec < 0 else False,
            #                     scale=1,
            #                     formatWithValue=[None,None,"low"],
            #                     #customizeNuisanceAttributes={".*AngCoeff4" : {"scale" : 1, "shapeType": "shapeNoConstraint"}},
            #                     labelsByAxis=["PtV", "YVBin", "Helicity"],
            #                     systAxesFlow=[], # only bins in acceptance in this call
            #                     skipEntries=[{"helicitySig" : [0,6,7,8]}], # removing last three indices out of 9 (0,1,...,7,8) corresponding to A5,6,7
            #                     splitGroup={f"{nuisanceBaseName}_Helicity{ihel}" : f".*{nuisanceBaseName}.*Helicity{ihel}" for ihel in [0, 1, 2, 3, 4]},
            #                     # splitGroup={f"{nuisanceBaseName}CorrPtQ" : f".*{nuisanceBaseName}CorrPtQ"},
            #                     preOpMap=
            #                             self.apply_theoryAgnostic_normVar_uncertainty(scale_hists,sign=None,helicities=self.args.helicitiesToInflate, scale=self.args.theoryAgnosticBandSize, rebin_axes=["ptVgenSig"]),
            #                         ),
            # self.card_tool.addSystematic("yieldsTheoryAgnostic",
            #                     rename=f"{nuisanceBaseName}CorrYQ",
            #                     **common_noi_args,
            #                     mirror=True,
            #                     symmetrize = None,
            #                     systAxes=self.poi_axes,
            #                     processes=["signal_samples"],
            #                     baseName=f"{nuisanceBaseName}CorrYQ_",
            #                     noConstraint=True if self.args.priorNormXsec < 0 else False,
            #                     scale=1,
            #                     formatWithValue=[None,None,"low"],
            #                     #customizeNuisanceAttributes={".*AngCoeff4" : {"scale" : 1, "shapeType": "shapeNoConstraint"}},
            #                     labelsByAxis=["PtV", "YVBin", "Helicity"],
            #                     systAxesFlow=[], # only bins in acceptance in this call
            #                     skipEntries=[{"helicitySig" : [0,6,7,8]}], # removing last three indices out of 9 (0,1,...,7,8) corresponding to A5,6,7
            #                     splitGroup={f"{nuisanceBaseName}_Helicity{ihel}" : f".*{nuisanceBaseName}.*Helicity{ihel}" for ihel in [0, 1, 2, 3, 4]},
            #                     # splitGroup={f"{nuisanceBaseName}CorrYQ" : f".*{nuisanceBaseName}CorrYQ"},
            #                     preOpMap=
            #                             self.apply_theoryAgnostic_normVar_uncertainty(scale_hists,sign=None,helicities=self.args.helicitiesToInflate, scale=self.args.theoryAgnosticBandSize, rebin_axes=["absYVgenSig"]),
            #                         ),



    def add_theoryAgnostic_uncertainty(self):
        if self.args.analysisMode == "theoryAgnosticPolVar":
            self.add_theoryAgnostic_polVar_uncertainty()
        elif self.args.muRmuFPolVar == True:
            self.add_muRmuF_polVar_uncertainty()
        else:
            self.add_theoryAgnostic_normVar_uncertainty()
